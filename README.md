# Финальный проект. Recommendation System

[Project One-Pager](./one_pager.md) — Краткое описание проекта на одной странице.

## Обзор
Этот проект реализует ML-систему для сервиса рекомендаций на основе модели SasRec.

**Основные возможности:**
- **API**: FastAPI сервис.
- **Хранилище данных**: PostgreSQL для хранения истории пользователей и результатов предсказаний. Kafka в качестве брокера сообщений между ML моделью и API.
- **Пользовательский интерфейс**: Streamlit-приложение с поддержкой выбора пользователей и визуализации результатов.
- **Мониторинг**: Prometheus и Grafana для отслеживания метрик.
- **Аналитика**: dbt для построения витрин.

## Архитектура
Система состоит из следующих Docker-контейнеров:

1.  **`api` (FastAPI)**:
    -   Входная точка. Принимает HTTP-запросы от клиентов.
    -   **Producer**: Отправляет задачи в Kafka топик `inference.requests`.
    -   Создает запись в БД.
    -   Предоставляет эндпоинты для получения списка пользователей и истории взаимодействия.

2.  **`worker` (Python/PyTorch)**:
    -   **Consumer**: Читает задачи из топика `inference.requests`.
    -   Загружает модель SasRec.
    -   Выполняет предсказание.
    -   **Producer**: Отправляет результат в топик `inference.results`.

3.  **`kafka` & `zookeeper`**:
    -   Брокер сообщений для асинхронной связи между API и Worker.
    -   **Топики и участники**:
        -   `inference.requests`: Очередь задач на предсказание.
            -   **Producer**: `api` сервис (отправляет `request_id` и историю).
            -   **Consumer**: `worker` сервис (читает, выполняет инференс).
        -   `inference.results`: Очередь готовых результатов.
            -   **Producer**: `worker` сервис (отправляет результат после успешного инференса).
            -   **Consumers**:
                1.  `db_writer`: Сохраняет результат в PostgreSQL.
                2.  `ui`: Отображает результат пользователю.
        -   `system.control`: Управление состоянием системы.
            -   **Producer**: `trainer` (сообщает об обновлении модели).
            -   **Consumer**: `worker` (получает сигнал Hot-Reload для обновления весов без перезапуска).

4.  **`db_writer`**:
    -   Слушает топик `inference.results`.
    -   Обновляет статус задач в PostgreSQL на `COMPLETED` и сохраняет JSON-результат.

5.  **`postgres`**:
    -   Основное хранилище данных.
    -   **Таблицы**:
        -   `interactions`: Хранит историю действий пользователей (`user_id`, `item_id`, `created_at`).
        -   `predictions`: Хранит статус и результат запросов (`request_id`, `status`, `result_json`).

6.  **`ui` (Streamlit)**:
    -   Веб-интерфейс для взаимодействия с системой.
    -   Позволяет выбирать пользователей из БД или вводить историю вручную.
    -   **Consumer**: Слушает топик `inference.results` для отображения результата в реальном времени.

7.  **`seeder`**:
    -   Сервис-утилита. Запускается один раз при старте.
    -   Наполняет таблицу `interactions` тестовыми данными.

8.  **`dbt`**:
    -   Запускает SQL-скрипты для построения витрин данных.
    -   Рассчитывает метрики DAU, количество предсказаний и др. (см. `dm_daily_stats`).

9.  **`prometheus` & `grafana`**:
    -   Стек мониторинга. Prometheus собирает метрики с API, Grafana их визуализирует.

## Мониторинг

Система экспортирует метрики в Prometheus, которые визуализируются в Grafana. Автоматически преднастроенный дашборд доступен по адресу [http://localhost:3000](http://localhost:3000).

### Доступные метрики

**1. API Service (`api`)**
*   `http_requests_total`: Общее количество HTTP запросов (RPS).
*   `http_request_duration_seconds`: Гистограмма времени ответа API.

**2. Worker Service (`worker`)**
*   **Throughput**: `worker_processed_total` — Количество обработанных задач на инференс.
*   **Latency**: `worker_inference_latency_seconds` — Время выполнения самого инференса модели.
*   **Errors**: `worker_errors_total` — Счетчик ошибок при обработке.

**3. Data Drift**
*   **History Length Distribution** (`worker_history_length`): Тепловая карта длин входных последовательностей истории. Помогает понять профиль пользователя (холодный/активный).
*   **Score Distribution** (`worker_prediction_score`): Тепловая карта распределения скоров уверенности модели (Top-K). Сдвиг этого распределения может сигнализировать о деградации качества модели (Concept Drift).

## Аналитика (dbt)
Система использует **dbt** для трансформации данных и построения аналитических витрин. Сервис обновляет витрины каждый час.

### Пайплайн данных

1.  **Sources** (`sources.yml`):
    *   `postgres.interactions`: Сырые события взаимодействия пользователей.
    *   `postgres.predictions`: Лог всех запросов к ML сервису.

2.  **Staging** (`models/staging/`):
    *   `stg_interactions`: Очистка дубликатов.
    *   `stg_predictions`: Фильтрация только успешных (`COMPLETED`) предсказаний и приведение типов.

3.  **Marts** (`models/marts/`):
    *   `dm_daily_stats`: Основная витрина. Агрегирует данные по дням.
        *   **DAU**: Количество уникальных пользователей за день.
        *   **Total Predictions**: Общее количество выполненных рекомендаций.

### Как проверить работу dbt
1.  **Посмотреть логи сервиса**:
    ```bash
    docker-compose logs dbt
    ```
    *Вы должны увидеть сообщения `OK created sql table model...`*

2.  **Запустить расчет вручную**:
    ```bash
    docker-compose exec dbt dbt run --profiles-dir .
    ```

3.  **Проверить витрины в базе данных**:
    ```bash
    docker-compose exec postgres psql -U sasrec -d sasrec -c "SELECT * FROM dm_daily_stats ORDER BY report_date DESC;"
    ```

## Как запустить локально

1.  **Требования**: Установленный Docker и Docker Compose.

2.  **Запуск**:
    ```bash
    git clone <repository_url>
    cd MLOps-final-project
    docker-compose up --build
    ```
    *Команда соберет образы, запустит все сервисы и автоматически наполнит базу данных тестовыми пользователями.*

3.  **Доступ к сервисам**:
    *   **UI**: [http://localhost:8501](http://localhost:8501)
    *   **API Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)
    *   **Grafana**: [http://localhost:3000](http://localhost:3000) (Login/Pass: `admin` / `admin`)
    *   **Prometheus**: [http://localhost:9090](http://localhost:9090)

## Использование UI
1.  Перейдите на [http://localhost:8501](http://localhost:8501).
2.  В боковой панели выберите режим:
    *   **Select User**: Выберите одного из сгенерированных пользователей (`user_1` ... `user_100`). Вы увидите его историю взаимодействия. Можно выбрать длину истории (слайдер).
    *   **Manual Input**: Введите ID товаров вручную через запятую (например: `10, 20, 30`).
3.  Нажмите кнопку **"Get Recommendations"**.
4.  Дождитесь обработки запроса. Результат отобразится в виде таблицы и графика распределения скоров.

## Переобучение модели

Для запуска процесса переобучения на свежих данных из базы:

1.  **Запустите Trainer**:
    ```bash
    docker-compose --profile training run --rm trainer
    ```
    *Сервис выгрузит данные из Postgres, обучит модель и сохранит новый чекпоинт в папке `checkpoints/`.*

2.  **Обновление модели (Hot-Reload)**:
    Система автоматически подхватит новую модель. Воркер получит сообщение через Kafka (`system.control`) и перезагрузит веса без остановки обслуживания запросов.
